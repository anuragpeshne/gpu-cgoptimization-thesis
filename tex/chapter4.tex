\chapter{BLOCK PREFETCHING} \label{block prefetching}

This chapter presents the idea of prefetching block data from server to hide the
network transfer time.

\section{Background}
To process a large array, SIAL programs are written to process blocks of array
in a pardo loop to spread the work across workers. After processing is done, the
block is sent back to the server. This is a very common pattern in SIAL. There
is network bound operation surrounding compute bound operations.

%\hline
\begin{algorithm}  {Processing large array}
%\hline %
\singlespacing

\begin{algorithmic}[1]
%\caption{Processing large array in SIAL}\label{alg:euclid}
\Loop\Comment{SIAL do/pardo loop}
\State $GET\ A[i, j]$\Comment{Request data from server asynchronously}
\State $GET\ B[j, k]$\Comment{Network bound}
\State $t\_result[j, k] \gets A[i, j] \times B[j, k]$\Comment{Compute bound}
\State $CALL\ compute\_fun(t\_result[j, k])$\Comment{Compute bound}
\State $PUT\ AB[i, k] \gets t\_result[i, k]$\Comment{Network bound}
\EndLoop
%\hline
\end{algorithmic}
\end{algorithm}

It is clear from the pseudocode that the computing resources is wasted due to
waiting for the data to be ready. To improve the wait time of the compute
operation, prefetching of the blocks from server over network using MPI was
implemented.

\section{Implementation of Prefetching}

\subsection{pardo Loop Implementation}
While the \textbf{do} loop in SIAL is simple as it goes over the indices
linearly, there are multiple implementation of pardo loop itself, which differ
in the distribution of indices and thus blocks over workers:
\begin{itemize}
\item \textbf{SequentialPardoLoop}: it behaves similar to a simple do loop,
  except this loop can loop over multiple indices.
\item \textbf{StaticTaskAllocParallelPardoLoop}: the indices for this loop are
  determined statically by distributing the block over worker in a cyclic fashion.
\item \textbf{BalancedTaskAllocParallelPardoLoop}: to support symmetric arrays,
  SIAL has \textbf{where} construct in loops which prunes the iteration based on
  some programmer defined condition. This loop respects that pruning.
\item \textbf{FragLoopManager} and its sub classes: SIAL supports large sparse
  arrays and to loop over them efficiently SIAL has implements for pardo loop.
\end{itemize}
Due to such varieties of implementation of pardo and to not affect how
subsequent indices are generated and yet to have a unified prefetching
mechanism, it was necessary to implement a lazy prefetch mechanism which will
probe for indices as needed. A lazy implementation would also support any other
future implementation of dynamic distribution of blocks according to the work
load on workers, at same time also gives freedom to vary number of prefetched
blocks.

\subsection{Lazy Indices Probing}
Each class implement pardo have a function \textbf{update} which calculates the
set of indices and populates interpreter state from where the blocks are
determined.

%\hline
\begin{algorithm}  {Update Indices}
%\hline %
\singlespacing

\begin{algorithmic}[1]
%\caption{Processing large array in SIAL}\label{alg:euclid}
\Procedure{update\_indices}{}
\ForAll{$indices\ in\ loop$}
\State $old\_index\_val \gets
interpreter\_state.indices[index\_slot]$\Comment{get current index value}
\State $new\_val \gets old\_index\_val + 1$\Comment{Increment the index as needed}
\State $interpreter\_state.indices[index\_slot] \gets new\_val$\Comment{update
  the interpreter state}
\EndFor
\EndProcedure
%\hline
\end{algorithmic}
\end{algorithm}


The mechanism to generate next indices and changing the state was
divided into two functions: \textbf{get\_next\_indices} and \textbf{update}. And
another function \textbf{peek\_indices(n)} was written to probe and form a list
of subsequent \textbf{n} indices.

\textbf{get\_next\_indices(current\_indices) $\rightarrow$ next\_indices} is now
made a pure function which takes in set of current indices and outputs set of
\textit{next} indices.

\begin{algorithm}  {get\_next\_indices}
\singlespacing

\begin{algorithmic}[1]
\Function{get\_next\_indices}{$current\_indices$}
\ForAll{$indx\_id\ in\ loop$}
\State $old\_index\_val \gets current\_indices[index\_id]$\Comment{get current index value}
\State $new\_val \gets old\_index\_val + 1$\Comment{Increment the index as needed}
\State $new\_indices \gets new\_val$\Comment{update the index into new set of indices}
\EndFor%
\State \Return{$new\_indices$}\Comment{return new set without any side effects}
\EndFunction
%\hline
\end{algorithmic}
\end{algorithm}

The importance of \textbf{get\_next\_indices} of being pure function is that now
it can be composed with other function calls and be called multiple times without
fear of any side effects. \textbf{peek\_indices(n)} maintains a list of indices
and returns set of \textbf{n} indices is already computed or probes next set of
indices if needed by calling get\_next\_indices by passing latest set of
already calculated indices.

\begin{algorithm}  {peek\_indices(n)}
\singlespacing

\begin{algorithmic}[1]
\Function{peek\_indices}{$computed\_indices, n$}
\If length(computed\_indices) > 0
  \State $peeked\_indices \gets computed\_indices[0]$
  \State \Return append(peeked\_indices, peek\_indices(rest(computed\_indices), n
  - 1)
\EndIf
\State $old\_index\_val \gets current\_indices[index\_id]$\Comment{get current index value}
\State $new\_val \gets old\_index\_val + 1$\Comment{Increment the index as needed}
\State $new\_indices \gets new\_val$\Comment{update the index into new set of indices}
\State \Return{$new\_indices$}\Comment{return new set without any side effects}
\EndFunction
%\hline
\end{algorithmic}
\end{algorithm}