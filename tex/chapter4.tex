\chapter{BLOCK PREFETCHING}\label{block prefetching}

This chapter presents the idea of prefetching block data from server to hide the
network transfer time.

\section{Background}
To process a large array which cannot fit into memory of a single node, a typical
workflow in SIAL consists of requesting a block of array from server in a
\texttt{pardo} looping construct by each participating worker. After processing
it, the resulting block is sent back to server. This common pattern can be
summarized as single or multiple network bound operation surrounding one or more
compute bound operations.

%\hline
\begin{algorithm}  {Processing large array}
%\hline %
\singlespacing

\begin{algorithmic}[1]
%\caption{An example of typical workflow in SIAL}\label{alg:SIALWorkFLow}
\Loop\Comment{SIAL do/pardo loop}
\State $GET\ A[i, j]$\Comment{Request data from server asynchronously}
\State $GET\ B[j, k]$\Comment{Network bound}
\State $t\_result[j, k] \gets A[i, j] \times B[j, k]$\Comment{Compute bound}
\State $CALL\ compute\_fun(t\_result[j, k])$\Comment{Compute bound}
\State $PUT\ AB[i, k] \gets t\_result[i, k]$\Comment{Network bound}
\EndLoop
%\hline
\end{algorithmic}
\end{algorithm}

It is clear from the pseudocode that the computing resources are wasted while
waiting for the data to be ready. To improve the wait time of the compute
operation, non-blocking MPI call \texttt{MPI\_Irecv} was exploited to prefetch
the blocks from server over network.

\section{Implementation of Prefetching}

\subsection{pardo Loop Implementation}
While the \texttt{do} loop which iterates over the indices one by one in SIAL is
simple, there are multiple implementation of \texttt{pardo} loop, which differ
in the distribution of indices and thus distribution of blocks over workers:
\begin{itemize}
\item \texttt{SequentialPardoLoop}: it behaves similar to a simple do loop,
  except this loop can loop over multiple indices.
\item \texttt{StaticTaskAllocParallelPardoLoop}: the indices for this loop are
  determined statically by distributing the block over worker in a cyclic fashion.
\item \texttt{BalancedTaskAllocParallelPardoLoop}: to support symmetric arrays,
  SIAL has \texttt{where} construct in loops which prunes the iteration based on
  some programmer defined condition. Due to such pruning there is a non zero
  probability that all of the iterations are assigned to one particular worker.
  This loop evaluates the \texttt{where} clauses and distributes the valid iteration
  over workers in a balanced way.
\item \texttt{FragLoopManager} and its sub classes: SIAL supports large sparse
  arrays. To loop over them efficiently SIAL has various implementations of
  fragmented pardo loops. These loops have knowledge of internal structure of the
  sparse arrays and thus can skip over rows and columns having non useful values.
\end{itemize}
Due to so many varieties of implementation of \texttt{pardo} looping construct
and to support future implementations of indices generation schemes, it is
important to keep the mechanism of prefetching separate from indices generation.
For this a lazy prefetching mechanism was implemented which will probe for indices
as needed dynamically. A lazy implementation would also give freedom to vary number
of prefetched blocks at runtime.

\subsection{Lazy Indices Probing}
Each class implementing \texttt{pardo} have a function \texttt{update} which
calculates the values of set of indices and populates interpreter state. This
state is used by interpreter to calculate blocks using array and index values.

%\hline
\begin{algorithm}  {$update\_indices() \rightarrow bool$}
%\hline %
\singlespacing

\begin{algorithmic}[1]
%\caption{Processing large array in SIAL}\label{alg:euclid}
\Procedure{update\_indices}{}
\ForAll{$indices\ in\ loop$}
\State $old\_index\_val \gets
interpreter\_state.indices[index\_slot]$\Comment{get current index value}
\State $new\_val \gets old\_index\_val + 1$\Comment{Increment the index as needed}
\If{$new\_val \geq upper\_bound[index\_slot]$}
  \State $new\_val \gets lower\_seg[index\_slot]$
\EndIf
\State $interpreter\_state.indices[index\_slot] \gets new\_val$\Comment{update
  the interpreter state}
\EndFor
\If{$all\ indices\ reached\ upper\_bound$}
  \State \Return{false}
\Else
  \State \Return{true}
\EndIf
\EndProcedure
%\hline
\end{algorithmic}
\end{algorithm}

To implement lazy probing, the work done by procedure \texttt{update} is divided
into multiple procedures:

\begin{itemize}
\item \texttt{get\_next\_indices} produces set of \textit{next} indices purely
  based on indices passed as parameter rather than getting directly from interpreter
  state. This allows us to produce series of indices independent of state of
  interpreter.
  \begin{algorithm}  {get\_next\_indices([index]) $\rightarrow$ [index]}
    \singlespacing

    \begin{algorithmic}[1]
      \Function{get\_next\_indices}{$current\_indices$}
      \ForAll{$indx\_id\ in\ loop$}
      \State $old\_index\_val \gets current\_indices[index\_id]$\Comment{get current index value}
      \State $new\_val \gets old\_index\_val + 1$\Comment{Increment the index as needed}
      \State $new\_indices \gets new\_val$\Comment{update the index into new set of indices}
      \EndFor%
      \State \Return{$new\_indices$}\Comment{return new set independent of interpreter state}
      \EndFunction
      % \hline
    \end{algorithmic}
  \end{algorithm}

\item \texttt{peek\_indices} returns set of indices and internally takes care of
  maintaining and creating list of indices \textit{lazily}. It calls the procedure
  \texttt{get\_next\_indices} to produce next set of indices by passing the last
  set of indices in the list as needed. It increases the length of list by 1 if
  the set of indices requested for is last one in the list and there are more indices
  in the loop.

  \begin{algorithm}  {peek\_indices(IndexList::iterator) $\rightarrow$ [index]}
    \singlespacing

    \begin{algorithmic}[1]
      \Function{peek\_indices}{$it$}
      \If{$IndexList.empty()$}
      \State \Return $[\ ]$
      \Else
      \State $peekedIndices \gets *it$
      \If{$next(it) == IndexList.end()$}
      \State $new\_indices \gets get\_next\_indices(*it)$
      \State $IndexList.insert\_after(it, new\_indices)$
      \EndIf
      \State \Return $peekedIndices$
      \EndIf
      \EndFunction
      % \hline
    \end{algorithmic}
  \end{algorithm}

\item \texttt{prefetch\_indices} remembers the last set of indices returned to each
  \texttt{GET} statement and returns the next set of indices on call. It remembers
  by mapping the position of indices in list to \texttt{line numbers} of each
  \texttt{GET}.

\item \texttt{update} is now changed to simply pop the first set of indices from
  the list and update interpreter state so that other modules can find the value
  of current indices. This decreases the length of list by 1.
  \begin{algorithm}  {update\_indices() $\rightarrow$ bool}
    \singlespacing

    \begin{algorithmic}[1]
      \Function{update\_indices}{}
      \State $current\_indices \gets peek\_indices(IndexList.begin())$
      \If{$length(current\_indices) > 0$}\Comment{is there any more iteration}
      \State $Indexlist.pop()$
      \ForAll{$index\_slot\ in\ current\_indices $}
      \State $interpreter\_state.indices[index\_slot] \gets current\_indices[index\_slot]$
      \EndFor
      \State \Return $true$
      \Else
      \State \Return $false$
      \EndIf
      \EndFunction
      % \hline
    \end{algorithmic}
  \end{algorithm}
\end{itemize}

In all the functions \texttt{peek\_indices} and \texttt{update} can be modeled
as producer and consumer problem on a bounded buffer.

\tikzstyle{table}=[rectangle split, rectangle split parts=2, draw,
    rectangle split horizontal,minimum width=8cm]
\begin{tikzpicture}[list/.style={rectangle split, rectangle split parts=7,
    draw, rectangle split horizontal}, >=stealth, start chain]

  \node[list,on chain] (A) {};
  \node[list,on chain] (B) {};
  \node[list,on chain] (C) {};
  \node[on chain,draw,inner sep=6pt] (D) {};
  \draw (D.north east) -- (D.south west);
  \draw (D.north west) -- (D.south east);
  \draw[*->] let \p1 = (A.seven), \p2 = (A.center) in (\x1,\y2) -- (B);
  \draw[*->] let \p1 = (B.seven), \p2 = (B.center) in (\x1,\y2) -- (C);
  \draw[*->] let \p1 = (C.seven), \p2 = (C.center) in (\x1,\y2) -- (D);

  \node[table] (head) at ++(0, -4) {Line Number \nodepart{second} Reference};
  \node[table,below=of head] (row1) {101};
  \node[table,below=of row1] (row2) {102};

  \draw[*->] (row1.second) -- (B.south);
  \draw[*->] (row2.second) -- (C.south);
\end{tikzpicture}