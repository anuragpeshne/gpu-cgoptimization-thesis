\chapter{CONCLUSION AND FUTURE WORK}\label{conclusion}
Two approaches to enhance the looping constructs and improve the runtime efficiency
of SIAL interpreter are presented in this thesis. One applies the old technique of
data block prefetching to SIA. Other improves
the utilization of GPU to execute Super Instructions on GPU and make way to support
other compute devices in future.

Though prefetching makes subsequent requests to a server efficient by reducing or
eliminating \texttt{wait\_time}, it makes the first request to the server expensive.
Thus to make up for it, the length of the range of indices should be long enough. Hit
ratio, as defined in section~\ref{sec:hit_ratio}, can be used as a metric to evaluate
the performance of prefetching. As seen in section~\ref{sec:bp_molecule}, prefetching
helps in reducing overall \texttt{wait\_time} when most of the \texttt{wait\_time}
is due to blocking for data block transfer over the network.

Future work includes exploiting the provision to dynamically vary the number of blocks
to prefetch to strike a balance between high cost of the initial request and relatively
cheap subsequent requests.

Executing Super Instructions on GPU can speed up the computation for bigger block
sizes. Transferring blocks between GPU and main memory is expensive but it can be
avoided or reduced by directly collecting to or sending blocks from GPU memory.
Page locked memory
can improve memory transfer speed by invoking DMA and bypassing CPU. But page locked
memory is expensive as compared to dynamically allocated memory. Page locked
memory blocks can be cached and served with high cache hit ratio.

Further improvement in utilization of GPU can be achieved by implementing more
super instructions on GPU and a way to easily port user defined super instructions
to GPU; By exploiting the asynchronous memory synchronization between GPU memory
and main memory by looking ahead for instruction which needs the memory
to be transferred and initiating the asynchronous transfer as soon as data is ready.
And exploring the feasibility of having access to GPU on servers and implementing
RDMA to transfer memory blocks between workers and servers. Lastly, implementing
an advanced caching mechanism for page locked memory blocks can be worked upon to have
more efficient caching mechanism.
