\chapter{BACKGROUND: SUPER INSTRUCTION ARCHITECTURE} \label{background}

This chapter introduces the SIA, ACES4, block-based
programming, the design of workers and servers, SIAL, parallel looping constructs
and design of GPU implementation.

\section{SIA}
The SIA is a special purpose, domain agnostic,
parallel programming framework which is engineered for solving very large
computation. SIA expresses the computation in terms of multi-dimensional arrays and
instructions, which operate on complete arrays. This way of expressing a computation
is different from conventional programming
languages wherein computation is described in terms of individual floating point
number and operations which work on these individual numbers. Aggregating
individual numbers into blocks results in better performance and higher utilization
of resources. However, this adds considerable complexity to programs since now
the programmer has to be careful of the index arithmetic and designing algorithms to loop
over entire blocks. Algorithms in SIA can be directly expressed in terms of
blocks. This gives the performance benefits of using block and at the same time relieves
programmer from error-prone work of dealing with indices and looping. Expressing
computation in terms of blocks has multiple performance advantages: moving data in terms
of blocks is more efficient since it has less overhead per individual number
and runtime can overlap computation and network operation since transferring these
blocks will take significant time, resulting in better overall utilization of resources.
There is an added advantage of expressing computation in terms of blocks in a parallel
framework, that the work can be distributed among participating nodes in a natural
way.

Since these multi-dimensional arrays can be too
large to hold in physical memory of a single processor, they are broken into
blocks or super numbers. These super numbers are used as input to special instructions
written to operate on blocks instead of floating point numbers. These
instructions are called as super instructions. Section~\ref{siaarch} describes how
these blocks are managed among participating processors.

SIA can execute instructions on blocks in parallel on multiple processors. To
facilitate movement of blocks among parallel execution units, server-client
architecture is used. SIA provides SIAL, a block-oriented domain specific
language (DSL), which supports expressing algorithms using blocks and a way
to write super instructions, which are domain specific, in an optimized way. The
following sections describe details of working of server-client architecture,
SIAL, and constructs in it.

\section{Architecture of SIA}\label{siaarch}
SIA can execute instructions in parallel over multiple processors. It can be
deployed and scaled on multiple nodes in a high performance computing cluster
using MPI for internode communication. Since the
multidimensional arrays involved in the calculations can be extremely large for
the memory of a single processor, SIA divides the arrays into chunks of
manageable sizes. These chunks are distributed to different processors and the
processors can work on these chunks concurrently.

SIA supports arrays of size greater than the combined memory of all processors
involved in computation by providing the facility of storing the chunks which are
not \textit{hot}, that is the chunks which are not going to be used soon, on
larger, although slower, memory on hard drives. This swapping of blocks is automatic
and transparent to the programmer. To facilitate the movement of data among
processing units and swapping out blocks to hard drives, SIA divides available
processors into two groups: workers and servers --- the workers are responsible for
actual execution of instructions on the blocks, while the servers make sure blocks
are served to and from the workers. The division of the number of the servers versus the number
of the workers is chosen by SIA but can be overridden by passing command line
arguments.

\section{SIAL}
SIAL is a programming language provided for expressing problems of the target
domain. The idea behind SIAL is to keep the domain problem separate from
platform problem. SIAL programs are written by the domain experts
whereas the intricacies involved in execution of SIAL programs, like distribution of
data, parallel execution, memory management, runtime optimizations, are handled
by computing experts.

SIAL, apart from providing programmers with conventional constructs such as
conditional constructs, looping constructs, procedures, way to import other SIAL
programs like general purpose programming language, also provides special parallel looping construct and a way
to define domain-specific block operation or \textit{super instruction}. It
has several common block operations built in. The
parallel looping construct, \texttt{pardo}, loops over multiple indices and
distributes blocks to different processors. This construct is of special
interest to us since the optimizations done using GPUs are mostly done in the
interpretation of this looping construct.

As mentioned above, domain experts can write their own domain-specific
super instructions which take in single or multiple blocks and output a resulting block. These
instructions can be written in C, C++ or Fortran. Since these languages are much
closer to the hardware, these super instructions can be written in a very
optimized way. Further more, this facility can be exploited to port the super instructions to
other computing devices such as GPU by writing these super instructions using
Nvidia CUDA.

\subsection{SIAL Interpreter}
SIA consists of SIAL compiler which translates human-readable SIAL text to
machine friendly bytecode. This bytecode is interpreted by SIAL interpreter.
Since this interpretation happens at runtime, the interpreter is able to optimize the
execution based on resources available at runtime. If interpreter finds GPU
accessible, it may execute some part of the SIAL program on GPU and if it
doesn't find it, then it can automatically fallback to CPU. Similarly, there are
various optimizations implemented which depends on the amount of physical memory
present on the processor.

\section{Block Structure}
As described above, instead of processing data as a single floating point
number, SIA processes blocks of floating point numbers. These blocks are chunks
of even larger multidimensional arrays. Blocks are represented inside SIAL
interpreter using \texttt{Block} class. SIA supports heterogeneous computing
using other computing devices such as GPUs. Since GPUs have their own device memory
which is separate from main processor memory, there is a facility in
\texttt{Block} class to represent the block memory in other
computing devices. Along with member attributes which represent block metadata
and member functions which act on the block, the Block class has pointers to
the memory location on each computation unit: CPU, GPU and support for more
computing device such as Intel Xeon Phi.

The \texttt{Block} class depending upon the active computing device will return the
appropriate device memory address. There is also a logic build into the \texttt{Block}
class to automatically synchronize memory for various devices, so that if one
device edits the block and then in next instruction, another device wants
to read the block, the block memory will be automatically synchronized and the
next device will read updated memory. This is done by maintaining version numbers
for each memory and then updating the memory based upon the version numbers when
it is accessed.

\section{Executing Super Instructions on GPU}
There are two ways in which GPUs are exploited in SIA to obtain high concurrency.
First, the super instructions can be written in CUDA.
Using CUDA, these instructions can make use of low-level hardware
features and domain knowledge to fine-tune the implementation. Secondly, some of
the general purpose block operations such as matrix multiplication, addition,
scaling, tensor contraction can be implemented for GPU in the interpreter
itself. These operations can be imported from highly optimized libraries such as
Nvidia CuBLAS.

The SIAL interpreter takes care of executing GPU or CPU implementation of an
operation based upon availability of implementations and other factors such as
the size of input and output.

\section{Overview of ACES}
ACES4 is an implementation of SIA for chemical computation. It has been executed
on a variety of architectures but is specially optimized to enable
calculations on leadership-class supercomputers. Using ACES4, computational chemists
try to find approximate solutions to the electronic SchroÌˆdinger equation using Coupled cluster
methods. There exist other methods to calculate approximate solutions but Coupled
cluster methods, although computationally expensive, are one of the most accurate methods.
The chemical computation done using ACES4 uses data of high dimensions. A typical calculation in this domain
takes as input the geometry of a molecular system and a choice of single
particle orbitals as the basis to expand the many-electron quantum-mechanical wave
function. The complex algorithms, which produce properties of the molecular
system, can easily require arrays of double precision floating point upto
several hundred Gigabytes. Of these arrays, at least three need rapid access and
are usually stored in RAM, the rest that are used less frequently can be stored
on disk. SIA architecture is very suitable for these kinds of calculations since
the workers can work on parts of array concurrently and the servers can swap out
less frequently used arrays to disk.
